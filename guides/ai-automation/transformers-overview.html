<!--
================================================================================
🎉 GUIDE METADATA FOR AUTO-DETECTION 🎉
================================================================================
Edit the JSON below to classify your guide automatically.
The auto-detector (generate-manifest-auto.js) will read this metadata.

CATEGORIES AVAILABLE:
🧪 AI & Automation     - AI, ChatGPT, Machine Learning, Automation, Web Scraping, React, Python
💼 Career             - Career Prep, CV, Presentations, Skills, Professional Development
🎨 Creative Studio    - Design, Canva, Video Editing, Midjourney, UI/UX, Graphics
📊 Data & Business    - Data Analysis, Power BI, Excel, Marketing, SQL, Analytics
📚 Digital Basics     - Terminal, GitHub, Internet, File Management, Fundamentals
🚀 Technology         - Docker, IoT, Automotive, Cloud, DevOps, Infrastructure

================================================================================
INSTRUCTIONS:
1. Replace [שם המדריך] with your guide name (will appear in catalog)
2. Choose an appropriate emoji (🎨 🐍 📊 💻 ⚖️ etc.)
3. Pick ONE category from the list above
4. Add a short description (50 chars max)
5. Save & run: npm run auto
================================================================================
-->

<!--
{
  "guide_metadata": {
    "name": "סקירה מקיפה של ארכיטקטורת הטרנספורמר: מהיסודות ליישומים מתקדמים",
    "icon": "🤖",
    "category": "AI & Automation",
    "description": "מדריך מקיף לארכיטקטורת הטרנספורמר ב-AI.",
    "course_code": "DL-NLP-701-2024",
    "session_number": 5
  }
}
-->

<!DOCTYPE html>
<html lang="he" dir="rtl">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <!-- SEO Meta Tags -->
    <title>סקירה מקיפה של ארכיטקטורת הטרנספורמר: מהיסודות ליישומים מתקדמים | Deep Learning for Natural Language Processing | LearningHub</title>
    <meta name="description" content="מדריך מעמיק לארכיטקטורת הטרנספורמר – הבסיס למודלי שפה גדולים ובינה מלאכותית מודרנית. למד על עקרונותיה, יישומיה ויתרונותיה.">
    <meta name="keywords" content="טרנספורמר, מודלי שפה גדולים, למידת מכונה, עיבוד שפה טבעית, בינה מלאכותית, קשב עצמי, LLM, Attention, Deep Learning for Natural Language Processing, DL-NLP-701-2024, מדריך, לימוד, קורס חינמי, הדרכה מקצועית, EduManage, LearningHub">
    <meta name="author" content="LearningHub Academy - LearningHub">
    <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1">
    <meta name="language" content="Hebrew">
    <meta name="revisit-after" content="7 days">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="סקירה מקיפה של ארכיטקטורת הטרנספורמר: מהיסודות ליישומים מתקדמים | Deep Learning for Natural Language Processing">
    <meta property="og:description" content="מדריך מקיף לארכיטקטורת הטרנספורמר ב-AI.">
    <meta property="og:image" content="https://image.pollinations.ai/prompt/Minimalist%2C%20modern%2C%20tech%20vector%20art%20of%20interconnected%20neural%20network%20nodes%20forming%20a%20transformer%20architecture%2C%20with%20data%20flow%20arrows%20and%20a%20subtle%20glowing%20effect.%20Abstract%20and%20clean.%20minimalist%20flat%20vector%20art%20style%20high%20quality%204k">
    <meta property="og:url" content="https://learninghub.co.il/courses/DL-NLP-701-2024/transformers-overview.html">
    <meta property="og:site_name" content="LearningHub - פורטל הלמידה והחדשנות">
    <meta property="og:locale" content="he_IL">
    <meta property="article:author" content="LearningHub">
    <meta property="article:section" content="AI & Automation">
    <meta property="article:tag" content="טרנספורמר, מודלי שפה גדולים, למידת מכונה, עיבוד שפה טבעית, בינה מלאכותית, קשב עצמי, LLM, Attention">
    <meta property="article:published_time" content="2025-12-15">
    <meta property="article:modified_time" content="2025-12-15">
    
    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="סקירה מקיפה של ארכיטקטורת הטרנספורמר: מהיסודות ליישומים מתקדמים | Deep Learning for Natural Language Processing">
    <meta name="twitter:description" content="מדריך מקיף לארכיטקטורת הטרנספורמר ב-AI.">
    <meta name="twitter:image" content="https://image.pollinations.ai/prompt/Minimalist%2C%20modern%2C%20tech%20vector%20art%20of%20interconnected%20neural%20network%20nodes%20forming%20a%20transformer%20architecture%2C%20with%20data%20flow%20arrows%20and%20a%20subtle%20glowing%20effect.%20Abstract%20and%20clean.%20minimalist%20flat%20vector%20art%20style%20high%20quality%204k">
    <meta name="twitter:site" content="@LearningHubIL">
    <meta name="twitter:creator" content="@LearningHubIL">
    
    <!-- Additional SEO Meta Tags -->
    <meta name="theme-color" content="#1a1a2e">
    <meta name="msapplication-TileColor" content="#1a1a2e">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="https://learninghub.co.il/courses/DL-NLP-701-2024/transformers-overview.html">
    
    <!-- Alternate Languages -->
    <link rel="alternate" hreflang="he" href="https://learninghub.co.il/courses/DL-NLP-701-2024/transformers-overview.html">
    <link rel="alternate" hreflang="x-default" href="https://learninghub.co.il/courses/DL-NLP-701-2024/transformers-overview.html">
    
    <!-- Preconnect for Performance -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="preconnect" href="https://edu-manage.org">
    
    <!-- DNS Prefetch -->
    <link rel="dns-prefetch" href="//fonts.googleapis.com">
    <link rel="dns-prefetch" href="//edu-manage.org">
    
    <!-- Fonts with Performance Optimization -->
    <link
        href="https://fonts.googleapis.com/css2?family=Heebo:wght@300;400;500;700;900&family=Frank+Ruhl+Libre:wght@400;700;900&family=JetBrains+Mono:wght@400;600&display=swap"
        rel="stylesheet">
    
    <!-- Favicon and Icons -->
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    
    <!-- Global CSS -->
    <link rel="stylesheet" href="../../public/global.css">
    
    <!-- Mermaid JS (Injected for diagrams) -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            mermaid.initialize({
                startOnLoad: true,
                theme: 'base',
                themeVariables: {
                    primaryColor: '#e8f4fd',
                    primaryTextColor: '#1a1a2e',
                    primaryBorderColor: '#6c5ce7',
                    lineColor: '#6c5ce7',
                    secondaryColor: '#f4f4f4',
                    tertiaryColor: '#fff'
                },
                flowchart: {
                    htmlLabels: true,
                    curve: 'basis'
                }
            });
        });
    </script>
    
    <!-- Schema.org Structured Data -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "Article",
        "headline": "סקירה מקיפה של ארכיטקטורת הטרנספורמר: מהיסודות ליישומים מתקדמים",
        "description": "מדריך מעמיק לארכיטקטורת הטרנספורמר – הבסיס למודלי שפה גדולים ובינה מלאכותית מודרנית. למד על עקרונותיה, יישומיה ויתרונותיה.",
        "image": "https://image.pollinations.ai/prompt/Minimalist%2C%20modern%2C%20tech%20vector%20art%20of%20interconnected%20neural%20network%20nodes%20forming%20a%20transformer%20architecture%2C%20with%20data%20flow%20arrows%20and%20a%20subtle%20glowing%20effect.%20Abstract%20and%20clean.%20minimalist%20flat%20vector%20art%20style%20high%20quality%204k",
        "author": {
            "@type": "Organization",
            "name": "LearningHub Academy",
            "url": "https://learninghub.co.il"
        },
        "publisher": {
            "@type": "Organization",
            "name": "EduManage",
            "logo": {
                "@type": "ImageObject",
                "url": "https://edu-manage.org/logo.png"
            }
        },
        "datePublished": "2025-12-15",
        "dateModified": "2025-12-15",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://learninghub.co.il/courses/DL-NLP-701-2024/transformers-overview.html"
        },
        "articleSection": "AI & Automation",
        "keywords": "טרנספורמר, מודלי שפה גדולים, למידת מכונה, עיבוד שפה טבעית, בינה מלאכותית, קשב עצמי, LLM, Attention",
        "inLanguage": "he-IL",
        "isAccessibleForFree": true,
        "educationalLevel": "Beginner to Advanced",
        "learningResourceType": "Tutorial",
        "teaches": "Skills related to סקירה כללית של רובוטריקים ",
        "about": {
            "@type": "Course",
            "name": "Deep Learning for Natural Language Processing",
            "courseCode": "DL-NLP-701-2024"
        }
    }
    </script>
    
    <!-- Page-specific styles -->
    <style>
        :root {
            --theme-primary: #1a1a2e;    /* צבע ראשי של המדריך */
            --theme-accent: #6c5ce7;     /* צבע מבטא */
            --theme-light: #a29bfe;      /* צבע בהיר */
        }

        header {
            background: linear-gradient(135deg, var(--theme-primary) 0%, var(--theme-accent) 100%);
            color: white;
        }

        .concept-card {
            background: white;
            padding: 2rem;
            border-radius: 12px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
            margin-bottom: 2rem;
            border-right: 4px solid var(--theme-accent);
            overflow: hidden; /* Prevent diagram overflow */
        }

        /* Formatted Content Styles */
        .formatted-content p {
            margin-bottom: 1rem;
            line-height: 1.7;
            font-size: 1.05rem;
        }
        
        .formatted-content ul, .formatted-content ol {
            margin-bottom: 1.5rem;
            padding-right: 1.5rem;
        }

        .formatted-content li {
            margin-bottom: 0.5rem;
            line-height: 1.6;
        }

        .formatted-content strong {
            color: var(--theme-primary);
            font-weight: 700;
        }

        /* Diagrams */
        .diagram-container {
            background: #fdfdfd;
            border: 1px dashed #e0e0e0;
            border-radius: 8px;
            padding: 1rem;
            margin: 2rem 0;
            text-align: center;
        }

        .code-block {
            background: var(--theme-primary);
            color: #e8f4fd;
            padding: 1.5rem;
            border-radius: 8px;
            font-family: 'JetBrains Mono', monospace;
            direction: ltr;
            text-align: left;
            overflow-x: auto;
            margin: 1rem 0;
            position: relative;
        }

        .copy-btn {
            position: absolute;
            top: 0.5rem;
            left: 0.5rem;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            border: none;
            padding: 0.3rem 0.6rem;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.8rem;
        }

        .copy-btn:hover {
            background: rgba(255, 255, 255, 0.2);
        }

        /* טיזרים */
        .teaser-box {
            padding: 1.5rem;
            border-radius: 12px;
            margin: 1.5rem 0;
        }

        .teaser-idea {
            background: #e8f5e9;
            border-right: 4px solid #28a745;
        }

        .teaser-warning {
            background: #fff3cd;
            border-right: 4px solid #ffc107;
        }

        .teaser-secret {
            background: #f3e5f5;
            border-right: 4px solid #6f42c1;
        }

        .teaser-bonus {
            background: #e1f5fe;
            border-right: 4px solid #03a9f4;
        }

        .teaser-title {
            margin-bottom: 0.5rem;
            font-weight: 600;
        }

        .feature-image {
            width: 100%;
            height: auto;
            border-radius: 12px;
            margin: 2rem 0;
            box-shadow: 0 10px 30px rgba(0,0,0,0.15);
            max-height: 400px;
            object-fit: cover;
            border: 4px solid rgba(255,255,255,0.1);
        }
    </style>
</head>

<body>
    <!-- LMS Notice Banner -->
    <div style="background: linear-gradient(135deg, #28a745 0%, #20c997 100%); color: white; padding: 0.8rem 0; text-align: center; font-size: 0.9rem; position: sticky; top: 0; z-index: 1000; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
        <div style="max-width: 1200px; margin: 0 auto; display: flex; align-items: center; justify-content: center; gap: 1rem; flex-wrap: wrap;">
            <span>🎓 <strong>DL-NLP-701-2024: Deep Learning for Natural Language Processing</strong> // מפגש 5</span>
            <a href="https://edu-manage.org/" 
               style="background: white; color: #28a745; padding: 0.4rem 1rem; border-radius: 20px; text-decoration: none; font-weight: bold; font-size: 0.8rem; transition: all 0.3s;"
               onmouseover="this.style.background='#f8f9fa'"
               onmouseout="this.style.background='white'">
                לאזור האישי
            </a>
        </div>
    </div>

    <!-- Global Header -->
    <header class="global-header">
        <nav class="global-nav">
            <div class="nav-links">
                <a href="sitemap.html" class="nav-link">מפת האתר</a>
                <a href="categories.html" class="nav-link">קטגוריות</a>
                <a href="index.html" class="nav-link">ראשי</a>
            </div>
            <a href="index.html" class="nav-brand">
                <span class="logo">🎓</span>
                LearningHub
            </a>
            <button class="hamburger-menu" aria-label="תפריט ראשי">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </nav>
    </header>

    <!-- Breadcrumbs with Schema -->
    <nav class="breadcrumbs" aria-label="breadcrumb">
        <script type="application/ld+json">
        {
            "@context": "https://schema.org",
            "@type": "BreadcrumbList",
            "itemListElement": [
                {
                    "@type": "ListItem",
                    "position": 1,
                    "name": "דף הבית",
                    "item": "https://learninghub.co.il/index.html"
                },
                {
                    "@type": "ListItem",
                    "position": 2,
                    "name": "קטגוריות",
                    "item": "https://learninghub.co.il/categories.html"
                },
                {
                    "@type": "ListItem",
                    "position": 3,
                    "name": "Deep Learning for Natural Language Processing",
                    "item": "https://learninghub.co.il/courses/DL-NLP-701-2024"
                },
                {
                    "@type": "ListItem",
                    "position": 4,
                    "name": "סקירה מקיפה של ארכיטקטורת הטרנספורמר: מהיסודות ליישומים מתקדמים",
                    "item": "https://learninghub.co.il/courses/DL-NLP-701-2024/transformers-overview.html"
                }
            ]
        }
        </script>
        <a href="index.html">דף הבית</a>
        <span>/</span>
        <a href="categories.html">קטגוריות</a>
        <span>/</span>
        <a href="#">DL-NLP-701-2024</a>
        <span>/</span>
        <span class="current">סקירה מקיפה של ארכיטקטורת הטרנספורמר: מהיסודות ליישומים מתקדמים</span>
    </nav>

    <!-- Page Header with SEO Optimization -->
    <header class="page-header">
        <div class="header-content">
            <div style="font-size: 0.9rem; letter-spacing: 1px; text-transform: uppercase; opacity: 0.8; margin-bottom: 0.5rem;">
                LearningHub Academy // AI & Automation
            </div>
            <h1 itemprop="headline">🤖 סקירה מקיפה של ארכיטקטורת הטרנספורמר: מהיסודות ליישומים מתקדמים</h1>
            <p class="subtitle" itemprop="description">מדריך מעמיק לארכיטקטורת הטרנספורמר – הבסיס למודלי שפה גדולים ובינה מלאכותית מודרנית. למד על עקרונותיה, יישומיה ויתרונותיה.</p>
            
             <!-- Dynamic AI Image -->
            <img src="https://image.pollinations.ai/prompt/Minimalist%2C%20modern%2C%20tech%20vector%20art%20of%20interconnected%20neural%20network%20nodes%20forming%20a%20transformer%20architecture%2C%20with%20data%20flow%20arrows%20and%20a%20subtle%20glowing%20effect.%20Abstract%20and%20clean.%20minimalist%20flat%20vector%20art%20style%20high%20quality%204k" alt="סקירה כללית של רובוטריקים  illustration" class="feature-image" />

            <!-- Article Meta Information -->
            <div class="article-meta" style="margin-top: 1rem; font-size: 0.9rem; color: #666; display: flex; gap: 1rem; flex-wrap: wrap; justify-content: center;">
                <span itemprop="author" itemscope itemtype="https://schema.org/Organization">
                    👨‍🏫 מרצה: <span itemprop="name">צוות LearningHub Academy</span>
                </span>
                <span>📅 עודכן: <time itemprop="dateModified" datetime="2025-12-15">2025-12-15</time></span>
                <span>⏱️ זמן קריאה: 12 דקות</span>
                <span>📊 רמת קושי: בינוני</span>
            </div>
            
            <!-- Quick Navigation -->
            <div class="quick-nav" style="margin-top: 1.5rem; text-align: center;">
                <a href="#main-content" style="background: rgba(255,255,255,0.2); color: white; padding: 0.5rem 1rem; border-radius: 20px; text-decoration: none; margin: 0 0.5rem; font-size: 0.9rem;">
                    📖 תוכן המדריך
                </a>
                <a href="#lms-assignments" style="background: rgba(255,255,255,0.2); color: white; padding: 0.5rem 1rem; border-radius: 20px; text-decoration: none; margin: 0 0.5rem; font-size: 0.9rem;">
                    📋 מטלות להגשה
                </a>
                <a href="#join-course" style="background: rgba(255,255,255,0.2); color: white; padding: 0.5rem 1rem; border-radius: 20px; text-decoration: none; margin: 0 0.5rem; font-size: 0.9rem;">
                    🚀 לאזור האישי
                </a>
            </div>
        </div>
    </header>

    <!-- Main Content with SEO Structure -->
    <main class="page-container" id="main-content" itemscope itemtype="https://schema.org/Article">
        
        <!-- Table of Contents for SEO -->
        <div class="concept-card" style="background: #f8f9fa; border-right: 4px solid #007bff;">
            <h2>📋 סילבוס המפגש</h2>
            <nav aria-label="תוכן המדריך">
                <ol style="margin-right: 1.5rem; line-height: 1.8;">
                    <li><a href="#why-important" style="color: #007bff; text-decoration: none;">מבוא וחשיבות</a></li>
                    <li><a href="#part-1" style="color: #007bff; text-decoration: none;">היסודות התיאורטיים של ארכיטקטורת הטרנספורמר</a></li>
                    <li><a href="#part-2" style="color: #007bff; text-decoration: none;">יישום מעשי של הטרנספורמר: מבנה וזרימת נתונים</a></li>
                    <li><a href="#advanced" style="color: #007bff; text-decoration: none;">מושגים מתקדמים ואתגרים בטרנספורמרים</a></li>
                    <li><a href="#summary" style="color: #007bff; text-decoration: none;">סיכום המפגש</a></li>
                    <li><a href="#lms-assignments" style="color: #007bff; text-decoration: none;">מטלות להגשה (LMS)</a></li>
                </ol>
            </nav>
        </div>
        
        <!-- מבוא -->
        <section class="concept-card" id="why-important">
            <h2 itemprop="headline">למה הנושא חשוב בקורס "Deep Learning for Natural Language Processing"?</h2>
            <div itemprop="articleBody" class="formatted-content">
                <p>ארכיטקטורת הטרנספורמר חוללה מהפכה של ממש בתחום הבינה המלאכותית, ובפרט בעיבוד שפה טבעית (NLP). מאז הצגתה במאמר פורץ הדרך <strong>"Attention Is All You Need"</strong> בשנת 2017, היא הפכה לבסיס למודלי שפה גדולים (LLMs) דוגמת GPT ו-BERT.</p><p>מדריך זה יספק לכם סקירה מקיפה של הטרנספורמר, החל מעקרונות הליבה התיאורטיים שלו ועד ליישומים מעשיים ומושגים מתקדמים. נצלול לתוך מנגנון הקשב העצמי, נבין כיצד הוא מאפשר למודל ללמוד תלויות מורכבות בין מילים ברצף, ונדון כיצד ארכיטקטורה זו מתגברת על מגבלות של מודלים קודמים.</p>
            </div>
        </section>

        <!-- תוכן עיקרי - חלק 1 -->
        <section class="concept-card" id="part-1">
            <h2>1. היסודות התיאורטיים של ארכיטקטורת הטרנספורמר</h2>
            <div class="formatted-content">
                <p>בלב ארכיטקטורת הטרנספורמר עומד <strong>מנגנון הקשב העצמי (Self-Attention)</strong>. בניגוד למודלים רקורסיביים (RNNs) שמעבדים מילים ברצף, הקשב העצמי מאפשר למודל לשקול את כל המילים ברצף בו זמנית, ולחשב את החשיבות היחסית של כל מילה לכל מילה אחרת בתוך הרצף. זה מאפשר ללכוד תלויות ארוכות טווח בצורה יעילה בהרבה.</p><ul><li><strong>קשב רב-ראשי (Multi-Head Attention):</strong> במקום ראש קשב יחיד, הטרנספורמר משתמש במספר ראשי קשב הפועלים במקביל. כל ראש לומד ייצוג שונה של הקשב, מה שמעשיר את יכולת המודל ללכוד מידע מגוון מהקלט.</li><li><strong>קידוד עמדה (Positional Encoding):</strong> מכיוון שמנגנון הקשב העצמי אינו מכיל מידע אינהרנטי על סדר המילים ברצף, מוסיפים וקטורי קידוד עמדה ל-Embeddings של המילים. וקטורים אלו מקודדים את המיקום היחסי או המוחלט של כל מילה, ומאפשרים למודל להבין את הסדר הסמנטי.</li><li><strong>מבנה מקודד-מפענח (Encoder-Decoder):</strong> הטרנספורמר המקורי מורכב ממקודד (Encoder) ומפענח (Decoder). המקודד מעבד את רצף הקלט כולו ומייצר ייצוגים עשירים, ואילו המפענח משתמש בייצוגים אלו ובקלט קודם כדי לייצר את רצף הפלט.</li></ul>
            </div>
            
            <div class="diagram-container">
                <h4 style="margin-bottom: 1rem; color: #666;">תרשים מושגים (Concept Map)</h4>
                <div class="mermaid">
                    graph TD; A[ארכיטקטורת טרנספורמר] --> B{רכיבים מרכזיים}; B --> C[מנגנון קשב עצמי]; C --> C1[קשב רב-ראשי]; B --> D[קידוד עמדה]; B --> E[שכבות הזנה קדימה]; B --> F[נורמליזציה וחיבורים שיוריים]; A --> G[בלוק מקודד]; A --> H[בלוק מפענח]; G -- קשב צולב --> H;
                </div>
            </div>
            
            <!-- דוגמת קוד אם רלוונטי -->
            <div class="code-block">
                <button class="copy-btn" onclick="copyCode(this)">העתק</button>
                <pre>import torch
import torch.nn as nn

class SimpleSelfAttention(nn.Module):
    def __init__(self, embed_dim):
        super(SimpleSelfAttention, self).__init__()
        self.embed_dim = embed_dim
        # Query, Key, Value linear transformations
        self.query = nn.Linear(embed_dim, embed_dim)
        self.key = nn.Linear(embed_dim, embed_dim)
        self.value = nn.Linear(embed_dim, embed_dim)

    def forward(self, x):
        # x shape: (batch_size, seq_len, embed_dim)
        
        # 1. Linear projections to get Q, K, V
        Q = self.query(x) # (batch_size, seq_len, embed_dim)
        K = self.key(x)   # (batch_size, seq_len, embed_dim)
        V = self.value(x) # (batch_size, seq_len, embed_dim)

        # 2. Calculate attention scores: Q * K^T
        # K.transpose(-2, -1) swaps the last two dimensions (seq_len, embed_dim) -> (embed_dim, seq_len)
        scores = torch.matmul(Q, K.transpose(-2, -1)) # (batch_size, seq_len, seq_len)
        
        # 3. Scale scores to prevent vanishing gradients
        scores = scores / (self.embed_dim ** 0.5)

        # 4. Apply softmax to get attention weights
        attention_weights = torch.softmax(scores, dim=-1) # (batch_size, seq_len, seq_len)

        # 5. Multiply weights by V to get the output
        output = torch.matmul(attention_weights, V) # (batch_size, seq_len, embed_dim)
        return output

# Example usage:
# embed_dim = 64
# seq_len = 10
# batch_size = 2
# 
# model = SimpleSelfAttention(embed_dim)
# dummy_input = torch.randn(batch_size, seq_len, embed_dim)
# output = model(dummy_input)
# print(f"Input shape: {dummy_input.shape}")
# print(f"Output shape: {output.shape}")
</pre>
            </div>
        </section>

        <!-- טיזר 1 - חומר למחשבה -->
        <div class="teaser-box teaser-idea">
            <h4 class="teaser-title" style="color: #28a745;">💡 חומר למחשבה</h4>
            <p><strong>האם ידעת ש...</strong> האם ידעתם שארכיטקטורת הטרנספורמר נולדה מתוך צורך לוותר על רשתות רקורסיביות (RNNs) כדי להאיץ את האימון במודלים ארוכים ולטפל טוב יותר בתלויות ארוכות טווח?</p>
        </div>

        <!-- תוכן עיקרי - חלק 2 -->
        <section class="concept-card" id="part-2">
            <h2>2. יישום מעשי של הטרנספורמר: מבנה וזרימת נתונים</h2>
            <div class="formatted-content">
                <p>הבנת זרימת הנתונים בתוך בלוקי הטרנספורמר חיונית ליישום מעשי. כל בלוק מקודד וכל בלוק מפענח מכיל מספר תת-שכבות, כאשר כל תת-שכבה מורכבת מחיבור שיורי (Residual Connection) ושכבת נורמליזציה (Layer Normalization) סביב הפונקציה הראשית שלה.</p><ul><li><strong>בלוק מקודד:</strong> מקבל קלט (מילים + קידוד עמדה), מעביר אותו דרך מנגנון קשב עצמי רב-ראשי, ולאחר מכן דרך רשת הזנה קדימה פשוטה (Feed-Forward Network).</li><li><strong>בלוק מפענח:</strong> מורכב משלוש תת-שכבות: קשב עצמי רב-ראשי <strong>מוסווה (Masked Multi-Head Self-Attention)</strong>, קשב רב-ראשי <strong>צולב (Multi-Head Cross-Attention)</strong> המקבל מפתחות וערכים מהמקודד, ושוב רשת הזנה קדימה. המסווה בקשב העצמי של המפענח מבטיח שהמודל יחזה את המילה הבאה רק על סמך המילים הקודמות, ללא הצצה קדימה.</li></ul><p>השילוב של רכיבים אלה מאפשר לטרנספורמר ללמוד ייצוגים עשירים ומורכבים של נתונים, תוך שמירה על יעילות חישובית גבוהה יחסית לאימון מקבילי.</p>
            </div>

             <div class="diagram-container">
                <h4 style="margin-bottom: 1rem; color: #666;">תהליך העבודה (Workflow)</h4>
                <div class="mermaid">
                    graph LR; A[קלט טקסט] --> B[Embedding + קידוד עמדה]; B --> C[בלוק מקודד 1]; C --> D[בלוק מקודד N]; D -- ייצוגים --> E[בלוק מפענח 1]; E --> F[בלוק מפענח N]; F --> G[שכבת פלט (Softmax)]; G --> H[פלט (מילה חזויה)]; E & F -- 'מפתחות וערכים' --> C & D; E -- 'קלט קודם' --> E; F -- 'קלט קודם' --> F;
                </div>
            </div>
            
            <!-- רשימה או שלבים -->
            <ol style="margin-right: 1.5rem; line-height: 1.8;">
                 <li><strong>שלב 1:</strong> <strong>הגדרת שכבת Embedding וקידוד עמדה:</strong> המרת מילים לווקטורים צפופים והוספת מידע על המיקום שלהן ברצף.</li>
                <li><strong>שלב 2:</strong> <strong>בניית מודול הקשב העצמי (Self-Attention):</strong> יצירת פונקציה שמחשבת את יחסי הגומלין בין כל אסימון ברצף לכל שאר האסימונים.</li>
                <li><strong>שלב 3:</strong> <strong>שילוב שכבות נורמליזציה וחיבורים שיוריים:</strong> הוספת Layer Normalization ו-Residual Connections כדי לייצב את האימון ולשפר את זרימת הגרדיאנטים.</li>
                <li><strong>שלב 4:</strong> <strong>הרכבת בלוק המקודד (Encoder Block):</strong> שילוב מנגנון הקשב העצמי ורשת הזנה קדימה עם הנורמליזציה והחיבורים השיוריים.</li>
                <li><strong>שלב 5:</strong> <strong>הרכבת בלוק המפענח (Decoder Block):</strong> בניית בלוק הכולל קשב עצמי מוסווה, קשב צולב (עם פלטי המקודד) ורשת הזנה קדימה.</li>
                <li><strong>שלב 6:</strong> <strong>בניית מודל הטרנספורמר המלא:</strong> חיבור מספר בלוקי מקודד ובלוקי מפענח ליצירת הארכיטקטורה השלמה.</li>
                <li><strong>שלב 7:</strong> <strong>אימון וחיזוי:</strong> אימון המודל על מערך נתונים גדול ושימוש בו לביצוע משימות כמו תרגום או יצירת טקסט.</li>
            </ol>
        </section>

        <!-- טיזר 2 - אזהרה -->
        <div class="teaser-box teaser-warning">
            <h4 class="teaser-title" style="color: #856404;">⚠️ רגע, עצור!</h4>
            <p><strong>שים לב:</strong> הזהרו: בנייה ואימון של מודלי טרנספורמר מאפס דורשים משאבי חישוב משמעותיים וידע עמוק בתכנות ובמתמטיקה. מומלץ להתחיל עם ספריות קיימות.</p>
        </div>

        <!-- תוכן מתקדם -->
        <section class="concept-card" id="advanced">
            <h2>3. מושגים מתקדמים ואתגרים בטרנספורמרים</h2>
            
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 1.5rem; margin: 1.5rem 0;">
                <div style="background: #f8f9fa; padding: 1.5rem; border-radius: 8px; border-right: 4px solid var(--theme-accent);">
                    <h3 style="color: var(--theme-primary); margin-bottom: 1rem;">וריאציות ושיפורים בארכיטקטורה</h3>
                    <ul style="margin-right: 1.5rem;">
                         <li><strong>טרנספורמרים דלילים (Sparse Transformers):</strong> מודלים המפחיתים את העלות החישובית של הקשב עבור רצפים ארוכים במיוחד.</li>
                        <li><strong>טרנספורמרים קונבולוציוניים (Convolutional Transformers):</strong> שילוב יתרונות של רשתות קונבולוציה עם מנגנון הקשב.</li>
                        <li><strong>מודלים ספציפיים:</strong> BERT (דו-כיווני למשימות הבנה), GPT (חד-כיווני למשימות יצירה), T5 (מודל מאוחד למגוון משימות).</li>
                        <li><strong>טרנספורמרים יעילים (Efficient Transformers):</strong> כמו Reformer, Performer, Linformer, המציעים דרכים חלופיות להפחית את מורכבות הקשב.</li>
                    </ul>
                </div>
                
                <div style="background: #f8f9fa; padding: 1.5rem; border-radius: 8px; border-right: 4px solid var(--theme-light);">
                    <h3 style="color: var(--theme-primary); margin-bottom: 1rem;">אתגרים ופתרונות עתידיים</h3>
                    <ul style="margin-right: 1.5rem;">
                         <li><strong>עלות חישובית:</strong> מנגנון הקשב דורש משאבי חישוב וזיכרון רבים, במיוחד עבור רצפים ארוכים. פתרונות כוללים קשב דליל, קשב מבוסס ליבה (kernel-based attention), ועוד.</li>
                        <li><strong>צורך בנתונים:</strong> אימון מודלי טרנספורמר גדולים דורש כמויות אדירות של נתונים, מה שמגביל את הנגישות. למידת העברה (Transfer Learning) באמצעות מודלים מאומנים מראש היא פתרון נפוץ.</li>
                        <li><strong>הטיה אתית:</strong> מודלים גדולים נוטים לשקף הטיות הקיימות בנתוני האימון, מה שמעלה שאלות אתיות וחברתיות. מחקר מתמקד בזיהוי והפחתת הטיות אלו.</li>
                        <li><strong>פרשנות והבנה:</strong> קשה להבין בדיוק כיצד מודלי טרנספורמר מגיעים להחלטותיהם. פיתוח כלים לפרשנות (Explainable AI) הוא תחום מחקר פעיל.</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- טיזר 3 - סוד קטן -->
        <div class="teaser-box teaser-secret">
            <h4 class="teaser-title" style="color: #6f42c1;">🤫 סוד קטן</h4>
            <p><strong>טעות נפוצה:</strong> סוד תעשייתי: רוב חברות הטכנולוגיה הגדולות אינן מאמנות מודלי טרנספורמר מאפס, אלא משתמשות במודלים מאומנים מראש (pre-trained) ומכווננות אותם למשימות ספציפיות (fine-tuning) – גישה יעילה בהרבה!</p>
        </div>

        <!-- מסקנות ויישום מעשי -->
        <section class="concept-card" id="summary" style="background: linear-gradient(135deg, var(--theme-primary) 0%, var(--theme-accent) 100%); color: white; border: none;">
            <h2 style="color: white;">🎯 סיכום המפגש</h2>
            
            <div style="background: rgba(255,255,255,0.1); padding: 1.5rem; border-radius: 12px; margin-bottom: 1.5rem;">
                <h3 style="color: white; margin-bottom: 1rem;">✅ מה למדנו היום?</h3>
                <ul style="margin-right: 1.5rem; line-height: 1.8;">
                     <li>ארכיטקטורת הטרנספורמר חוללה מהפכה של ממש בתחום עיבוד שפה טבעית ובבינה מלאכותית בכלל.</li>
                        <li>מנגנון הקשב העצמי הוא ליבת הטרנספורמר, המאפשר למודל להתייחס לכל חלקי הקלט בו זמנית וללכוד תלויות ארוכות טווח.</li>
                        <li>קידוד עמדה מספק למודל מידע חיוני על סדר המילים ברצף.</li>
                        <li>הטרנספורמר מתאפיין ביכולת לאימון מקבילי יעיל, מה שמאיץ משמעותית את תהליך הלמידה.</li>
                        <li>מודלי שפה גדולים (LLMs) מודרניים, כמו GPT ו-BERT, מבוססים כולם על ארכיטקטורת הטרנספורמר.</li>
                </ul>
            </div>

            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 1.5rem;">
                <div style="background: rgba(255,255,255,0.1); padding: 1.5rem; border-radius: 12px;">
                    <h3 style="color: white; margin-bottom: 1rem;">🚀 לקראת המפגש הבא</h3>
                    <ul style="margin-right: 1.5rem; line-height: 1.6;">
                         <li>חקור לעומק את מנגנון הקשב הרב-ראשי (Multi-Head Attention) ואת אופן פעולתו המתמטי.</li>
                        <li>נסה ליישם בלוק טרנספורמר בסיסי באמצעות ספריות למידה עמוקה כמו PyTorch או TensorFlow.</li>
                        <li>קרא את המאמר המקורי "Attention Is All You Need" כדי להבין את הרציונל והפרטים הטכניים.</li>
                        <li>התנסה עם ספריות כמו Hugging Face Transformers כדי לטעון ולהשתמש במודלים מאומנים מראש.</li>
                    </ul>
                </div>

                <div style="background: rgba(255,255,255,0.1); padding: 1.5rem; border-radius: 12px;">
                    <h3 style="color: white; margin-bottom: 1rem;">⚠️ דגשים חשובים</h3>
                    <ul style="margin-right: 1.5rem; line-height: 1.6;">
                        <li><strong>התעלמות מחשיבות קידוד העמדה:</strong> ללא קידוד עמדה, הטרנספורמר מאבד את מידע הסדר ברצף.</li>
                        <li><strong>אי הבנה של ההבדל בין קשב עצמי לקשב צולב:</strong> קשב עצמי מתייחס לאותו רצף, בעוד קשב צולב מקשר בין שני רצפים (לרוב קלט ופלט).</li>
                        <li><strong>ניסיון לאמן מודל טרנספורמר גדול ללא משאבי חישוב מספקים:</strong> מודלים אלו דורשים GPU חזקים וזיכרון רב.</li>
                        <li><strong>הזנחת שלבי נורמליזציה וחיבורים שיוריים:</strong> רכיבים אלה קריטיים ליציבות האימון ולמניעת בעיות גרדיאנטים.</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- משימות לשבוע הקרוב (LMS Assignments) -->
        <section class="concept-card" id="lms-assignments">
            <h2>📋 מטלות להגשה (מתוך מערכת הקורס)</h2>
            <p style="margin-bottom: 1.5rem; color: #666;">יש להגיש את המטלות הבאות דרך מערכת ה-LMS עד המועד הנקוב.</p>
            
            
        <div style="background: #e3f2fd; border: 2px solid #007bff; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem;">
            <div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 0.5rem;">
                <h3 style="color: #333; margin: 0; display: flex; align-items: center; gap: 0.5rem;">
                    <span>📋 מטלה</span> ניתוח מנגנון הקשב בטרנספורמר
                </h3>
                <span style="background: white; padding: 0.2rem 0.6rem; border-radius: 4px; font-size: 0.8rem; font-weight: bold; border: 1px solid rgba(0,0,0,0.1);">
                    משקל: 25%
                </span>
            </div>
            <p style="margin-bottom: 1rem; color: #444;">כתוב חיבור קצר (300-400 מילים) המתאר את מנגנון הקשב העצמי בטרנספורמר, את יתרונותיו לעומת רשתות RNN/LSTM, והסבר כיצד קשב רב-ראשי (Multi-Head Attention) משפר את ביצועיו. יש לכלול דוגמאות קצרות להמחשה.</p>
            
      <div style="margin-top: 1rem; background: #fff; padding: 1rem; border-radius: 8px; border: 1px solid #e0e0e0;">
        <h5 style="margin-top: 0; margin-bottom: 0.5rem; color: #555; font-size: 0.9rem;">📊 מחוון הערכה (Rubric)</h5>
        <table style="width: 100%; border-collapse: collapse; font-size: 0.85rem;">
          <thead>
            <tr style="background: #f9f9f9; text-align: right;">
              <th style="padding: 0.5rem; border-bottom: 2px solid #eee;">קריטריון</th>
              <th style="padding: 0.5rem; border-bottom: 2px solid #eee;">תיאור</th>
              <th style="padding: 0.5rem; border-bottom: 2px solid #eee;">נקודות</th>
            </tr>
          </thead>
          <tbody>
            
              <tr>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;"><strong>הסבר מנגנון הקשב העצמי</strong></td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">הבנה מעמיקה של מנגנון הקשב העצמי והסבר ברור.</td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">40</td>
              </tr>
            
              <tr>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;"><strong>השוואה למודלים רקורסיביים</strong></td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">השוואה מפורטת ומנומקת לרשתות RNN/LSTM.</td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">30</td>
              </tr>
            
              <tr>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;"><strong>הסבר קשב רב-ראשי</strong></td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">הסבר מדויק על תפקידו ויתרונותיו של קשב רב-ראשי.</td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">20</td>
              </tr>
            
              <tr>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;"><strong>איכות הכתיבה והניסוח</strong></td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">בהירות, לכידות וכתיבה אקדמית נאותה.</td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">10</td>
              </tr>
            
          </tbody>
        </table>
      </div>
    
        </div>
      
        <div style="background: #f3e5f5; border: 2px solid #6f42c1; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem;">
            <div style="display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 0.5rem;">
                <h3 style="color: #333; margin: 0; display: flex; align-items: center; gap: 0.5rem;">
                    <span>🚀 פרויקט</span> תרגיל תכנות: בלוק מקודד של טרנספורמר
                </h3>
                <span style="background: white; padding: 0.2rem 0.6rem; border-radius: 4px; font-size: 0.8rem; font-weight: bold; border: 1px solid rgba(0,0,0,0.1);">
                    משקל: 35%
                </span>
            </div>
            <p style="margin-bottom: 1rem; color: #444;">כתוב קוד Python (באמצעות PyTorch או TensorFlow) המיישם בלוק מקודד יחיד של טרנספורמר. הקוד צריך לכלול את מנגנון הקשב העצמי, שכבת Feed-Forward, נורמליזציה (LayerNorm) וחיבורים שיוריים. כלול הערות מפורטות והדגמה קצרה עם קלט דמה.</p>
            
      <div style="margin-top: 1rem; background: #fff; padding: 1rem; border-radius: 8px; border: 1px solid #e0e0e0;">
        <h5 style="margin-top: 0; margin-bottom: 0.5rem; color: #555; font-size: 0.9rem;">📊 מחוון הערכה (Rubric)</h5>
        <table style="width: 100%; border-collapse: collapse; font-size: 0.85rem;">
          <thead>
            <tr style="background: #f9f9f9; text-align: right;">
              <th style="padding: 0.5rem; border-bottom: 2px solid #eee;">קריטריון</th>
              <th style="padding: 0.5rem; border-bottom: 2px solid #eee;">תיאור</th>
              <th style="padding: 0.5rem; border-bottom: 2px solid #eee;">נקודות</th>
            </tr>
          </thead>
          <tbody>
            
              <tr>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;"><strong>יישום Self-Attention</strong></td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">נכונות היישום של מנגנון הקשב העצמי (Self-Attention).</td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">40</td>
              </tr>
            
              <tr>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;"><strong>יישום Feed-Forward</strong></td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">נכונות היישום של שכבת Feed-Forward.</td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">20</td>
              </tr>
            
              <tr>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;"><strong>LayerNorm ו-Residuals</strong></td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">שילוב נכון של Layer Normalization ו-Residual Connections.</td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">20</td>
              </tr>
            
              <tr>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;"><strong>איכות הקוד והתיעוד</strong></td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">בהירות הקוד, שימוש בהערות מפורטות, והדגמת קלט/פלט.</td>
                <td style="padding: 0.5rem; border-bottom: 1px solid #eee;">20</td>
              </tr>
            
          </tbody>
        </table>
      </div>
    
        </div>
      

            <!-- טיזר 4 - בונוס -->
            <div class="teaser-box teaser-bonus">
                <h4 class="teaser-title" style="color: #0277bd;">😎 בונוס (רשות)</h4>
                <p><strong>תרגיל אתגר:</strong> בונוס: מודלי טרנספורמר משמשים כיום לא רק למשימות שפה, אלא גם למשימות ראייה ממוחשבת (Vision Transformers), עיבוד אודיו, ואף רובוטיקה, מה שמדגים את הרבגוניות והכוח שלהם!</p>
            </div>
        </section>

        <!-- מסע המשתמש - חזרה ל-LMS -->
        <div class="concept-card" style="background: linear-gradient(135deg, #28a745 0%, #20c997 100%); color: white; border: none; position: relative; overflow: hidden;">
            <!-- רקע דקורטיבי -->
            <div style="position: absolute; top: -50px; right: -50px; width: 200px; height: 200px; background: rgba(255,255,255,0.1); border-radius: 50%; opacity: 0.3;"></div>
            <div style="position: absolute; bottom: -30px; left: -30px; width: 150px; height: 150px; background: rgba(255,255,255,0.1); border-radius: 50%; opacity: 0.2;"></div>
            
            <div style="position: relative; z-index: 2;">
                <h2 style="color: white; text-align: center; margin-bottom: 1.5rem;">🎯 סיימת את יחידת הלימוד!</h2>
                
                <div style="text-align: center; margin: 2rem 0;">
                    <div style="font-size: 3rem; margin-bottom: 1rem;">🚀</div>
                    <p style="font-size: 1.2rem; margin: 1.5rem 0; line-height: 1.6;">
                        <strong>חומר זה הוא חלק מקורס Deep Learning for Natural Language Processing (DL-NLP-701-2024)</strong><br>
                        יש לחזור לפורטל הקורס לצורך ביצוע המבחן המסכם והגשת המטלות.
                    </p>
                </div>

                <!-- כפתור חזרה ל-LMS לתלמידים רשומים -->
                <div style="text-align: center; margin: 2rem 0;">
                    <a href="https://edu-manage.org/" 
                       style="display: inline-block; background: white; color: #28a745; padding: 1rem 2.5rem; border-radius: 50px; text-decoration: none; font-weight: bold; font-size: 1.1rem; box-shadow: 0 4px 15px rgba(0,0,0,0.2); transition: all 0.3s; border: 3px solid white;"
                       onmouseover="this.style.background='#f8f9fa'; this.style.transform='translateY(-2px)'"
                       onmouseout="this.style.background='white'; this.style.transform='translateY(0)'">
                        🎓 חזרה לפורטל הקורס - EduManage
                    </a>
                </div>
            </div>
        </div>

        <!-- מדריכים קשורים -->
        <div class="concept-card">
            <h2 style="text-align: center; margin-bottom: 2rem;">📚 יחידות לימוד נוספות בקורס</h2>
            
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1.5rem; margin: 2rem 0;">
                
                <a href="#" style="background: white; color: var(--theme-primary); text-decoration: none; display: flex; flex-direction: column; align-items: center; padding: 1.5rem; border-radius: 12px; transition: transform 0.3s; box-shadow: 0 4px 15px rgba(0,0,0,0.1); border: 2px solid #f8f9fa;"
                   onmouseover="this.style.transform='translateY(-5px)'; this.style.boxShadow='0 8px 25px rgba(0,0,0,0.15)'"
                   onmouseout="this.style.transform='translateY(0)'; this.style.boxShadow='0 4px 15px rgba(0,0,0,0.1)'">
                    <span style="font-size: 2.5rem; margin-bottom: 1rem;">🧠</span>
                    <strong style="font-size: 1.1rem; margin-bottom: 0.5rem; text-align: center;">מבוא ללמידת מכונה עמוקה</strong>
                    <span style="font-size: 0.9rem; color: #666; text-align: center;">הכר את העקרונות הבסיסיים של רשתות נוירונים עמוקות, סוגי ארכיטקטורות נפוצות וכיצד הן פועלות.</span>
                </a>

                <a href="#" style="background: white; color: var(--theme-primary); text-decoration: none; display: flex; flex-direction: column; align-items: center; padding: 1.5rem; border-radius: 12px; transition: transform 0.3s; box-shadow: 0 4px 15px rgba(0,0,0,0.1); border: 2px solid #f8f9fa;"
                   onmouseover="this.style.transform='translateY(-5px)'; this.style.boxShadow='0 8px 25px rgba(0,0,0,0.15)'"
                   onmouseout="this.style.transform='translateY(0)'; this.style.boxShadow='0 4px 15px rgba(0,0,0,0.1)'">
                    <span style="font-size: 2.5rem; margin-bottom: 1rem;">💬</span>
                    <strong style="font-size: 1.1rem; margin-bottom: 0.5rem; text-align: center;">יסודות עיבוד שפה טבעית (NLP)</strong>
                    <span style="font-size: 0.9rem; color: #666; text-align: center;">למד על הכלים והטכניקות המרכזיות בעיבוד שפה טבעית, החל מ-Tokenization ועד ייצוגי מילים.</span>
                </a>

                <a href="#" style="background: white; color: var(--theme-primary); text-decoration: none; display: flex; flex-direction: column; align-items: center; padding: 1.5rem; border-radius: 12px; transition: transform 0.3s; box-shadow: 0 4px 15px rgba(0,0,0,0.1); border: 2px solid #f8f9fa;"
                   onmouseover="this.style.transform='translateY(-5px)'; this.style.boxShadow='0 8px 25px rgba(0,0,0,0.15)'"
                   onmouseout="this.style.transform='translateY(0)'; this.style.boxShadow='0 4px 15px rgba(0,0,0,0.1)'">
                    <span style="font-size: 2.5rem; margin-bottom: 1rem;">📚</span>
                    <strong style="font-size: 1.1rem; margin-bottom: 0.5rem; text-align: center;">מודלי שפה גדולים (LLM): עקרונות ויישומים</strong>
                    <span style="font-size: 0.9rem; color: #666; text-align: center;">צלול לעולם מודלי השפה הגדולים, עקרונותיהם, יכולותיהם, והאתגרים הכרוכים בפיתוחם.</span>
                </a>
            </div>
        </div>

    </main>
    
    <!-- FAQ Section for SEO -->
    <section class="concept-card" style="margin-top: 2rem;">
        <h2>❓ שאלות נפוצות על המפגש</h2>
        <div itemscope itemtype="https://schema.org/FAQPage">
            
            <div itemscope itemprop="mainEntity" itemtype="https://schema.org/Question">
                <h3 itemprop="name">מה ההבדל העיקרי בין טרנספורמר ל-RNN (רשת נוירונים רקורסיבית)?</h3>
                <div itemscope itemprop="acceptedAnswer" itemtype="https://schema.org/Answer">
                    <div itemprop="text">
                        <p>ההבדל העיקרי הוא שמנגנון הקשב העצמי בטרנספורמר מאפשר עיבוד מקבילי של כל חלקי הקלט, בניגוד ל-RNN המעבד רצפים באופן סדרתי. יתרון זה מוביל למהירות אימון גבוהה יותר, יכולת לטפל בתלויות ארוכות טווח טוב יותר, וביצועים עדיפים במשימות רבות.</p>
                    </div>
                </div>
            </div>
            <div itemscope itemprop="mainEntity" itemtype="https://schema.org/Question">
                <h3 itemprop="name">האם טרנספורמרים יכולים לשמש למשימות שאינן קשורות לשפה?</h3>
                <div itemscope itemprop="acceptedAnswer" itemtype="https://schema.org/Answer">
                    <div itemprop="text">
                        <p>בהחלט! למרות שהם התחילו ב-NLP, טרנספורמרים הותאמו בהצלחה למגוון רחב של משימות מעבר לשפה, כולל ראייה ממוחשבת (כמו Vision Transformers), עיבוד אודיו, ואף רובוטיקה, בזכות היכולת שלהם ללמוד יחסים מורכבים בין יחידות קלט בכל תחום.</p>
                    </div>
                </div>
            </div>
            <div itemscope itemprop="mainEntity" itemtype="https://schema.org/Question">
                <h3 itemprop="name">מהו קידוד עמדה (Positional Encoding) ומדוע הוא חשוב בארכיטקטורת הטרנספורמר?</h3>
                <div itemscope itemprop="acceptedAnswer" itemtype="https://schema.org/Answer">
                    <div itemprop="text">
                        <p>קידוד עמדה הוא מנגנון שמוסיף מידע על המיקום היחסי או המוחלט של אסימונים ברצף הקלט. הוא קריטי מכיוון שמנגנון הקשב העצמי אינו מכיל באופן טבעי מידע על סדר המילים. ללא קידוד עמדה, המודל לא היה מבחין בין משפטים כמו "הכלב נשך את הילד" לבין "הילד נשך את הכלב".</p>
                    </div>
                </div>
            </div>
            <div itemscope itemprop="mainEntity" itemtype="https://schema.org/Question">
                <h3 itemprop="name">כמה קשה לאמן מודל טרנספורמר גדול מאפס?</h3>
                <div itemscope itemprop="acceptedAnswer" itemtype="https://schema.org/Answer">
                    <div itemprop="text">
                        <p>אימון מודלי טרנספורמר גדולים (כמו GPT-3) דורש משאבי חישוב עצומים – אלפי מעבדי GPU למשך שבועות או חודשים – וסטים עצומים של נתונים. לכן, הוא נגיש בעיקר לחברות גדולות ומוסדות מחקר עם תקציבים משמעותיים. למטרות לימוד ופיתוח, ניתן להשתמש במודלים קטנים יותר או במודלים מאומנים מראש (pre-trained models) ולבצע עליהם Fine-tuning.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Global Footer -->
    <footer class="global-footer">
        <div class="footer-container">
            <div class="footer-main">
                <div class="footer-brand">
                    <h3><span class="brand-icon">🎓</span> LearningHub</h3>
                    <p class="footer-description">
                        פורטל הלמידה והחדשנות של LearningHub Academy. כלים דיגיטליים, בינה מלאכותית ואוטומציה לכל מקצוע ותחום.
                    </p>
                </div>
                
                <div class="footer-section">
                    <h4>ניווט בקורס</h4>
                    <ul class="footer-links">
                        <li><a href="#" class="footer-link">סילבוס הקורס</a></li>
                        <li><a href="#" class="footer-link">לוח מודעות</a></li>
                        <li><a href="#" class="footer-link">ציונים והערכה</a></li>
                    </ul>
                </div>
                
                <div class="footer-section">
                    <h4>משאבים</h4>
                    <ul class="footer-links">
                        <li><a href="sitemap.html" class="footer-link">מפת האתר</a></li>
                        <li><a href="https://edu-manage.org/" class="footer-link">פורטל התלמידים</a></li>
                    </ul>
                </div>
                
                <div class="footer-section">
                    <h4>EduManage LMS</h4>
                    <ul class="footer-links">
                        <li><a href="https://edu-manage.org/" class="footer-link">כניסה לפורטל</a></li>
                        <li><a href="#" class="footer-link">תמיכה טכנית</a></li>
                    </ul>
                </div>
            </div>
            
            <div class="footer-bottom">
                <div class="footer-copyright">
                    <div>© 2025 <a href="https://edu-manage.org/" style="color: inherit; text-decoration: none;">EduManage</a> • מערכת לניהול פדגוגי</div>
                </div>
            </div>
        </div>
    </footer>

    <!-- Global JavaScript -->
    <script src="../../public/global.js"></script>
    
    <!-- Page-specific JavaScript -->
    <script>
        // Copy code function
        function copyCode(btn) {
            const pre = btn.nextElementSibling;
            navigator.clipboard.writeText(pre.innerText);
            btn.innerText = 'הועתק!';
            setTimeout(() => btn.innerText = 'העתק', 2000);
        }
        
        // SEO and UX Enhancements
        document.addEventListener('DOMContentLoaded', function() {
            // Track reading progress for SEO signals
            let maxScroll = 0;
            window.addEventListener('scroll', function() {
                const scrollPercent = Math.round((window.scrollY / (document.body.scrollHeight - window.innerHeight)) * 100);
                if (scrollPercent > maxScroll) {
                    maxScroll = scrollPercent;
                    // Send engagement signal to analytics (if implemented)
                    if (typeof gtag !== 'undefined') {
                        gtag('event', 'scroll', {
                            'event_category': 'engagement',
                            'event_label': 'reading_progress',
                            'value': scrollPercent
                        });
                    }
                }
            });
            
            // Smooth scrolling for internal links
            document.querySelectorAll('a[href^="#"]').forEach(anchor => {
                anchor.addEventListener('click', function (e) {
                    e.preventDefault();
                    const target = document.querySelector(this.getAttribute('href'));
                    if (target) {
                        target.scrollIntoView({
                            behavior: 'smooth',
                            block: 'start'
                        });
                    }
                });
            });
        });
    </script>
</body>
</html>